{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOPb/8MSvGQ/3asX7Zgnwnn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandaVelizD/Fine-Tune-BERT-for-Text-Classification-with-TensorFlow/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWLkA1yw6bie"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.version.VERSION)"
      ],
      "metadata": {
        "id": "3HxrXM_x7MoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow==2.8.0"
      ],
      "metadata": {
        "id": "WnMyCTpy7ZnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --depth 1 -b v2.8.0 https://github.com/tensorflow/models.git"
      ],
      "metadata": {
        "id": "htqwhNry7jTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install requirements to use tensorflow/models repository\n",
        "!pip install -Uqr models/official/requirements.txt"
      ],
      "metadata": {
        "id": "zNlXdOmK9CF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-models-official\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import sys\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "sys.path.append('models')\n",
        "from official.nlp.data import classifier_data_lib\n",
        "from official.nlp.bert import tokenization\n",
        "from official.nlp import optimization\n",
        "\n"
      ],
      "metadata": {
        "id": "L8ArFLGcY9qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TF Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
      ],
      "metadata": {
        "id": "1OZpIS6oY_jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip\",\n",
        "                 compression=\"zip\", low_memory=False)\n",
        "df.shape\n"
      ],
      "metadata": {
        "id": "7Dx6zJW-aIWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(20)"
      ],
      "metadata": {
        "id": "ebjJO4dybZoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib==3.1.3\n",
        "!pip uninstall imgaug\n",
        "!pip install imgaug==0.4.0\n",
        "df.target.plot(kind=\"hist\", title=\"Target distribution\");\n"
      ],
      "metadata": {
        "id": "g2eMcYATbyA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create tf.data.Datasets for Training and evaluation\n"
      ],
      "metadata": {
        "id": "33wwYQMEZ1mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, remaining = train_test_split(df, random_state= 42, train_size=0.0075, stratify=df.target.values)\n",
        "valid_df, _ = train_test_split(remaining, random_state=42, train_size=0.00075, stratify= remaining.target.values)\n",
        "train_df.shape, valid_df.shape"
      ],
      "metadata": {
        "id": "Y-ZWcMpWZ_UR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(\"/cpu\"):\n",
        "  train_data =tf.data.Dataset.from_tensor_slices((train_df[\"question_text\"].values, train_df[\"target\"].values))\n",
        "  valid_data =tf.data.Dataset.from_tensor_slices((valid_df.question_text.values, valid_df.target.values))\n",
        "\n",
        "  for text, label in train_data.take(1):\n",
        "    print(text)\n",
        "    print(label)"
      ],
      "metadata": {
        "id": "fm1gVXT9kEg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download a Pre-trained BERT Model from Tensorflow Hub"
      ],
      "metadata": {
        "id": "Qsl6qgLplrSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Each line of the dataset is composed of the review text and its label\n",
        "- Data preprocessing consists of transforming text to BERT input features:\n",
        "input_word_ids, input_mask, segment_ids\n",
        "- In the process, tokenizing the text is done with the provided BERT model tokenizer\n",
        "\"\"\"\n",
        "label_list = [0,1] # Label categories\n",
        "max_seq_length = 128 # maximum length of (token) input sequences\n",
        "train_batch_size = 32\n",
        "\n",
        "# Get BERT layer and tokenizer:\n",
        "# More details here: https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\", trainable=True)\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "metadata": {
        "id": "HfNRhmX7lzLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.wordpiece_tokenizer.tokenize(\"hi, how are you doing?\")"
      ],
      "metadata": {
        "id": "oVeLJt44pR9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_tokens_to_ids(tokenizer.wordpiece_tokenizer.tokenize(\"hi, how are you doing?\"))"
      ],
      "metadata": {
        "id": "3fJbL99tpynd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll need to transform our data into a format BERT understands. This involves two steps. First, we create InputExamples using classifier_data_lib's constructor InputExample provided in the BERT library."
      ],
      "metadata": {
        "id": "K7XUSUNBrv8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This provides a function to convert row to input features and label\n",
        "\n",
        "def to_feature(text, label, label_list=label_list, max_seq_length=max_seq_length, tokenizer=tokenizer):\n",
        "  example = classifier_data_lib.InputExample(guide=None,\n",
        "                                             text_a = text.numpy(),\n",
        "                                             text_b =None,\n",
        "                                             label = label.numpy())\n",
        "  return (feature.input_ids, feature.input_mask. feature.segment_ids, feature.label_id)\n",
        "  \n",
        "  \n",
        "  "
      ],
      "metadata": {
        "id": "cMQU3J0krw6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wrap a python fuction into a Tensorflow op for Eager Execution"
      ],
      "metadata": {
        "id": "XR9V5D9oPXrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create a Tensorflow dataset and create a function that maps the raw text into the features this format that BERT requires\n",
        "def to_feature_map(tex, label):\n",
        "  input_ids, input_mask, segment_ids, label_id = tf.py_function(to_feature, inp=[text, label],\n",
        "                                                                Tout=[tf.int32, tf.int32, tf.int31, tf.int32])\n",
        "  input_ids.set_shape([max_seq_length])\n",
        "  inout_mask.set_shape([max_seq_length])\n",
        "  segment_ids.set_shape([max_seq_length])\n",
        "  label_id.set_shape([])\n",
        "\n",
        "  x = {\"input_word_ids\": input_ids,\n",
        "       \"input_mask\": input_mask,\n",
        "       \"input_type_ids\": segment_ids\n",
        "       }\n",
        "  return (x, label_id)\n"
      ],
      "metadata": {
        "id": "lvxTRCDAPWg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Tensorflow input pipeline with tf.data"
      ],
      "metadata": {
        "id": "HA3RVTiWT3f8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "blkunQpPT_0c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}